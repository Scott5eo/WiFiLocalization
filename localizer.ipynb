{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------Data Analysis--------------------------------------\n",
    "#ONLY RUN THIS CELL WHEN NEEDED! Otherwise its unnecessary.\n",
    "#data file name is in structure of \"label_attempt.json\" (e.g \"0_1.json\"), each file contains a list of dictionaries {\"MAC\":mac, \"RSSI\":rssi}\n",
    "#read through all files and create a set of MAC addresses that are in all files\n",
    "num_labels = 25\n",
    "num_attempts = 10\n",
    "mac_set = set()\n",
    "for label in range(num_labels):\n",
    "    for attempt in range(num_attempts):\n",
    "        file_name = str(label) + \"_\" + str(attempt) + \".json\"\n",
    "        with open(file_name, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            for item in data:\n",
    "                mac_set.add(item[\"MAC\"])\n",
    "mac_set = list(mac_set)\n",
    "print(\"Number of MAC addresses: \", len(mac_set))\n",
    "#save mac_set to a file\n",
    "with open(\"mac_set.txt\", \"w\") as f:\n",
    "    for mac in mac_set:\n",
    "        f.write(mac + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------Data Preprocessing--------------------------------------\n",
    "#read mac_set.txt and create a list\n",
    "mac_set = []\n",
    "with open(\"mac_set.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        mac_set.append(line.strip())\n",
    "\n",
    "#data training set\n",
    "data_set = []\n",
    "#read through all files\n",
    "for label in range(num_labels):\n",
    "    for attempt in range(num_attempts):\n",
    "        file_name = str(label) + \"_\" + str(attempt) + \".json\"\n",
    "        try:\n",
    "            with open(file_name,\"r\") as f:\n",
    "                data = json.load(f) #list of dictionary with mac, rssi\n",
    "                #create a 0 vector with length of mac_set\n",
    "                vector = np.zeros(len(mac_set))\n",
    "                #for each mac in data, find its index in mac_set and update the vector\n",
    "                for item in data:\n",
    "                    index = mac_set.index(item[\"MAC\"])\n",
    "                    vector[index] = item[\"RSSI\"]\n",
    "                #data point = (label, vector)\n",
    "                data_set.append((label, vector))\n",
    "        except:\n",
    "            print(\"Error in file: \", file_name)\n",
    "\n",
    "#data_set to dataframe\n",
    "df = pd.DataFrame(data_set, columns=[\"label\", \"vector\"])\n",
    "#print dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------Data Visualization--------------------------------------\n",
    "#vector is len(mac_set) long, which is a large dimension. So let's use auto encoder to reduce the dimension and visualize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[\"vector\"].values.tolist())\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(pca_data[:,0], pca_data[:,1], c=df[\"label\"], cmap=\"plasma\")\n",
    "plt.xlabel(\"First Principal Component\")\n",
    "plt.ylabel(\"Second Principal Component\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
